{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some examples of early encryption\n",
    "First, we need some reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available books: ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/fredrik/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from ngram import NGramModel\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "print(\"Available books:\", gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 models\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...] \t 1-gram model with 7811 unique keys\n",
      "['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ...] \t 1-gram model with 6132 unique keys\n",
      "['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', ...] \t 1-gram model with 6833 unique keys\n"
     ]
    }
   ],
   "source": [
    "fileids = gutenberg.fileids()[:3]\n",
    "\n",
    "def make_unigram_models(fileid):\n",
    "    from nltk.corpus import gutenberg\n",
    "    return NGramModel(gutenberg.words(fileid), 1)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "with Pool() as process_pool:\n",
    "    models = process_pool.map(make_unigram_models, fileids)\n",
    "\n",
    "print(\"Created %i models\" % len(models))\n",
    "\n",
    "for fid, m in zip(fileids, models):\n",
    "    print(gutenberg.words(fid), \"\\t\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of all english words in the corpus will also come in handy.\n",
    "\n",
    "This merges the words from the models. A word is defined as a key of lower case alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10294 english words in lexicon\n"
     ]
    }
   ],
   "source": [
    "def all_isalpha(word):\n",
    "    for c in word:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "english_words = set()\n",
    "for m in models:\n",
    "    words = [k[0].lower() for k in list(m.keys())]\n",
    "    english_words.update(set([w for w in words if all_isalpha(w)]))\n",
    "\n",
    "print(\"We have %i english words in lexicon\" % len(english_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples from the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['period', 'shocking', 'knoll', 'exit', 'religious', 'entitle', 'speedily', 'immortality', 'passionately', 'lectured', 'merchandise', 'began', 'unsuitableness', 'endeavoring', 'atoned', 'admiring', 'prettiness', 'encouraged', 'merits', 'select']\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "print(choices(list(english_words), k=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up some Austen books as training data for the character models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had b\n"
     ]
    }
   ],
   "source": [
    "austen_text = [gutenberg.raw(fid) for fid in ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt']]\n",
    "print(austen_text[0][:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "emma by jane austen   volume i  chapter i   emma woodhouse handsome clever and rich with a comfortable home and happy disposition seemed to unite some of the best blessings of existence and had lived nearly twentyone years in the world with very little to distress or vex her  she was the youngest of the two daughters of a most affectionate indulgent father and had in consequence of her sisters marriage been mistress of his house from a very early period  her mother had died too long ago for her to have more than an indistinct remembrance of her caresses and her place had been supplied by an ex\n",
      "1948591 characters in training data\n"
     ]
    }
   ],
   "source": [
    "def generate_alphabet(alpha, omega):\n",
    "    \"\"\"Set of the english alphabet\"\"\"\n",
    "    return set([chr(i) for i in range(ord(alpha), ord(omega)+1)]) \n",
    "\n",
    "def clean_text(text, allowed):\n",
    "    ret = text.lower()\n",
    "    strip = set(ret).difference(allowed)\n",
    "    if \" \" in allowed:\n",
    "        for s in strip:\n",
    "            if s in ['\\n', '\\t']:\n",
    "                ret = ret.replace(s, \" \")\n",
    "            else:\n",
    "                ret = ret.replace(s, \"\")\n",
    "    else:\n",
    "        for s in strip:\n",
    "            ret = ret.replace(s, \"\")\n",
    "    return ret\n",
    "\n",
    "alphabet = generate_alphabet('a', 'z') # Set of the english alphabet\n",
    "allowed_characters = set([' '])\n",
    "allowed_characters.update(alphabet)\n",
    "for i in range(len(austen_text)):\n",
    "    austen_text[i] = clean_text(austen_text[i], allowed_characters)\n",
    "\n",
    "print(\"---\")\n",
    "print(austen_text[0][:600])\n",
    "print(\"%i characters in training data\" % np.sum([len(t) for t in austen_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data cleaned, we are ready to create some character ngram models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 12 models\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "grid = {'data': austen_text, 'order': [1, 2, 3, 4]}\n",
    "\n",
    "def make_model(grid_point):\n",
    "    chars = list(grid_point['data'])\n",
    "    return NGramModel(chars, grid_point['order'])\n",
    "\n",
    "with Pool(processes=os.cpu_count()) as process_pool:\n",
    "    models = process_pool.map(make_model, ParameterGrid(grid))\n",
    "\n",
    "print(\"Created %i models\" % len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram model with 27 unique keys\n",
      "2-gram model with 560 unique keys\n",
      "3-gram model with 5365 unique keys\n",
      "4-gram model with 24737 unique keys\n"
     ]
    }
   ],
   "source": [
    "model_list = [None]*5\n",
    "for model in models:\n",
    "    if model_list[model.order_] is None:\n",
    "        model_list[model.order_] = model\n",
    "    else:\n",
    "        model_list[model.order_] = model_list[model.order_].union(model)\n",
    "\n",
    "unigram_model = model_list[1]\n",
    "print(unigram_model)\n",
    "bigram_model = model_list[2]\n",
    "print(bigram_model)\n",
    "trigram_model = model_list[3]\n",
    "print(trigram_model)\n",
    "quadgram_model = model_list[4]\n",
    "print(quadgram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram: a   dwvaoisgemhvdehctgnralsih fcsmeiedhtuev h ehu e dh  au iroe desatf ngwid aoaiowehteb r\n",
      "\n",
      "bigram: sy ki nd cobe witonghanoffuto o s habed sh winganderorrusand othess wngly he thed of score\n",
      "\n",
      "trigram: all then of thad afte a ch king muse shosto his expeas but by knight ady in elf em no hein\n",
      "\n",
      "quadgram: far own unner not eight from hers welliot purprishe green she rely more here excity  emma \n"
     ]
    }
   ],
   "source": [
    "print(\"unigram:\", \"\".join(unigram_model.predict_sequence(90)))\n",
    "print()\n",
    "print(\"bigram:\", \"\".join(bigram_model.predict_sequence(90)))\n",
    "print()\n",
    "print(\"trigram:\", \"\".join(trigram_model.predict_sequence(90)))\n",
    "print()\n",
    "print(\"quadgram:\", \"\".join(quadgram_model.predict_sequence(90)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the most common characters in this english text and their probabilities (from relative frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ',) - 0.19206\n",
      "('e',) - 0.10242\n",
      "('t',) - 0.06999\n",
      "('a',) - 0.06374\n",
      "('o',) - 0.06304\n",
      "('n',) - 0.05771\n",
      "('i',) - 0.05516\n",
      "('h',) - 0.05035\n",
      "('s',) - 0.05025\n",
      "('r',) - 0.04912\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for unigram, prob in list(ordered_ngrams(unigram_model))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caesar substitution crypto\n",
    "Maybe the most basic substitution crypto, based on charcter rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XMMNUKNMX\n"
     ]
    }
   ],
   "source": [
    "def caesar_encryption(word, offset=3):\n",
    "    enc = [chr(ord(char)+offset-len(alphabet)) if (ord(char)+offset)>ord('z') else chr(ord(char)+offset)\n",
    "           for char in word.lower() if char in alphabet]\n",
    "    return \"\".join(enc).upper()\n",
    "\n",
    "import random\n",
    "offset = random.randint(1, len(alphabet)-1)\n",
    "\n",
    "print(caesar_encryption(\"Et tu brute\", offset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for finding the key to an unknown cryptogram (assuming it's a caesar crypto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_to_alesia = \"YHUFLQJHWRULABRXUPRWKHUZDVDKDPVWHUDQGBRXUIDWKHUVPHOOVRIHOGHUEHUULHV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('H',) - 0.14925\n",
      "('U',) - 0.14925\n",
      "('V',) - 0.07463\n",
      "('D',) - 0.07463\n",
      "('R',) - 0.07463\n",
      "('W',) - 0.05970\n",
      "('L',) - 0.04478\n",
      "('K',) - 0.04478\n",
      "('P',) - 0.04478\n",
      "('O',) - 0.04478\n",
      "('B',) - 0.02985\n",
      "('I',) - 0.02985\n",
      "('G',) - 0.02985\n",
      "('X',) - 0.02985\n",
      "('Q',) - 0.02985\n",
      "('F',) - 0.01493\n",
      "('E',) - 0.01493\n",
      "('J',) - 0.01493\n",
      "('A',) - 0.01493\n",
      "('Z',) - 0.01493\n",
      "('Y',) - 0.01493\n"
     ]
    }
   ],
   "source": [
    "caesar_model = NGramModel(list(message_to_alesia), 1)\n",
    "for unigram, prob in list(ordered_ngrams(caesar_model)):\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_decode(text, offset):\n",
    "    ret = str()\n",
    "    for i in range(len(text)):\n",
    "        c = ord(text[i]) - offset\n",
    "        if c > ord('Z'):\n",
    "            c -= len(alphabet)\n",
    "        if c < ord('A'):\n",
    "            c += len(alphabet)\n",
    "        ret += chr(c)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vercingetorixyourmotherwasahamsterandyourfathersmellsofelderberries\n"
     ]
    }
   ],
   "source": [
    "n_key = 3\n",
    "message_from_caesar = caesar_decode(message_to_alesia, n_key)\n",
    "print(message_from_caesar.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something we can do to solve this, but the roman could not, was let a computer brute force this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 xgtekpigvqtkzaqwtoqvjgtycucjcouvgtcpfaqwthcvjgtuognnuqhgnfgtdgttkgu\n",
      "2 wfsdjohfupsjyzpvsnpuifsxbtbibntufsboezpvsgbuifstnfmmtpgfmefscfssjft\n",
      "3 vercingetorixyourmotherwasahamsterandyourfathersmellsofelderberries\n",
      "4 udqbhmfdsnqhwxntqlnsgdqvzrzgzlrsdqzmcxntqezsgdqrldkkrnedkcdqadqqhdr\n",
      "5 tcpaglecrmpgvwmspkmrfcpuyqyfykqrcpylbwmspdyrfcpqkcjjqmdcjbcpzcppgcq\n",
      "6 sbozfkdbqlofuvlrojlqebotxpxexjpqboxkavlrocxqebopjbiiplcbiaboyboofbp\n",
      "7 ranyejcapknetukqnikpdanswowdwiopanwjzukqnbwpdanoiahhokbahzanxanneao\n",
      "8 qzmxdibzojmdstjpmhjoczmrvnvcvhnozmviytjpmavoczmnhzggnjazgyzmwzmmdzn\n",
      "9 pylwchaynilcrsiolginbylqumubugmnyluhxsiolzunbylmgyffmizyfxylvyllcym\n",
      "10 oxkvbgzxmhkbqrhnkfhmaxkptltatflmxktgwrhnkytmaxklfxeelhyxewxkuxkkbxl\n",
      "11 nwjuafywlgjapqgmjeglzwjoskszseklwjsfvqgmjxslzwjkewddkgxwdvwjtwjjawk\n",
      "12 mvitzexvkfizopflidfkyvinrjryrdjkvireupfliwrkyvijdvccjfwvcuvisviizvj\n",
      "13 luhsydwujehynoekhcejxuhmqiqxqcijuhqdtoekhvqjxuhicubbievubtuhruhhyui\n",
      "14 ktgrxcvtidgxmndjgbdiwtglphpwpbhitgpcsndjgupiwtghbtaahdutastgqtggxth\n",
      "15 jsfqwbushcfwlmcifachvsfkogovoaghsfobrmciftohvsfgaszzgctszrsfpsffwsg\n",
      "16 irepvatrgbevklbhezbgurejnfnunzfgrenaqlbhesngurefzryyfbsryqreoreevrf\n",
      "17 hqdouzsqfadujkagdyaftqdimemtmyefqdmzpkagdrmftqdeyqxxearqxpqdnqdduqe\n",
      "18 gpcntyrpezctijzfcxzespchldlslxdepclyojzfcqlespcdxpwwdzqpwopcmpcctpd\n",
      "19 fobmsxqodybshiyebwydrobgkckrkwcdobkxniyebpkdrobcwovvcypovnoblobbsoc\n",
      "20 enalrwpncxarghxdavxcqnafjbjqjvbcnajwmhxdaojcqnabvnuubxonumnaknaarnb\n",
      "21 dmzkqvombwzqfgwczuwbpmzeiaipiuabmzivlgwcznibpmzaumttawnmtlmzjmzzqma\n",
      "22 clyjpunlavypefvbytvaolydhzhohtzalyhukfvbymhaolyztlsszvmlsklyilyyplz\n",
      "23 bkxiotmkzuxodeuaxsuznkxcgygngsyzkxgtjeuaxlgznkxyskrryulkrjkxhkxxoky\n",
      "24 ajwhnsljytwncdtzwrtymjwbfxfmfrxyjwfsidtzwkfymjwxrjqqxtkjqijwgjwwnjx\n",
      "25 zivgmrkixsvmbcsyvqsxlivaeweleqwxiverhcsyvjexlivwqippwsjiphivfivvmiw\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, len(alphabet)):\n",
    "    print(n, caesar_decode(message_to_alesia, n).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-one substitution crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDR0NT0DMNT0DHPT6XURPHNTHVP0TJXUVNTOHXO7HTGR77HJT6XURPHNT0DH3T5XT0DHTDXVNHTM0TNR3NT6XURPNT5XTDXUH\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Whats this then Romanes eunt domus People called Romanes they go the house It says Romans go home\"\"\"\n",
    "#def encrypt_substitution(text):\n",
    "text = text.lower()\n",
    "unenc = list(set(text))\n",
    "symbols = [c.upper() for c in alphabet]\n",
    "symbols.extend(list(\"0123456789\"))\n",
    "s = list(symbols)\n",
    "random.shuffle(s)\n",
    "enc = s[:len(unenc)]\n",
    "\n",
    "key = dict()\n",
    "for a, b in zip(unenc, enc):\n",
    "    key[a] = b\n",
    "\n",
    "def substitute(text, encryption_key, replace=\"-\"):\n",
    "    ret = str()\n",
    "    for c in text:\n",
    "        if c in encryption_key.keys():\n",
    "            ret += encryption_key[c]\n",
    "        else:\n",
    "            if replace is not None:\n",
    "                ret += replace\n",
    "            else:\n",
    "                ret += c\n",
    "    return ret\n",
    "\n",
    "enc_text = substitute(text, key)\n",
    "print(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 'T',\n",
       " 'o': 'X',\n",
       " 'g': '5',\n",
       " 'w': 'F',\n",
       " 'l': '7',\n",
       " 'r': '6',\n",
       " 'm': 'U',\n",
       " 'c': 'G',\n",
       " 'p': 'O',\n",
       " 'h': 'D',\n",
       " 'n': 'P',\n",
       " 'i': 'M',\n",
       " 'e': 'H',\n",
       " 's': 'N',\n",
       " 'a': 'R',\n",
       " 'y': '3',\n",
       " 'd': 'J',\n",
       " 'u': 'V',\n",
       " 't': '0'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': ' ',\n",
       " 'X': 'o',\n",
       " '5': 'g',\n",
       " 'F': 'w',\n",
       " '7': 'l',\n",
       " '6': 'r',\n",
       " 'U': 'm',\n",
       " 'G': 'c',\n",
       " 'O': 'p',\n",
       " 'D': 'h',\n",
       " 'P': 'n',\n",
       " 'M': 'i',\n",
       " 'H': 'e',\n",
       " 'N': 's',\n",
       " 'R': 'a',\n",
       " '3': 'y',\n",
       " 'J': 'd',\n",
       " 'V': 'u',\n",
       " '0': 't'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_key = dict()\n",
    "for a, b in [(k, key[k]) for k in key.keys()]:\n",
    "    reverse_key[b] = a\n",
    "reverse_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats this then romanes eunt domus people called romanes they go the house it says romans go home\n"
     ]
    }
   ],
   "source": [
    "print(substitute(enc_text, reverse_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepted_in_jerusalem = \"\"\"GPMCPIMEHMIRJXDCRMIRPMDH1PJCJXDH1MRP7IEHCMT4TIPLMRPJPMDQMIRJXDCRMIXMIRPML7EHM7D1EPH2PM2R7LWPJMRPJPM7H1MQE07IPTMGESPTMWP1JXXLMETMRPJPMR7KEHCMCJ7WWP1MRETMGESPMGPMEHSXJLMQE07IPMIR7IMTRPMETMEHMXDJM2DTIX14M7H1MSXJIRGEIRMETTDPMXDJM1PL7H1TMIRP4KPMW0P1MDTMGREIPMIRPMW7TI7J1TMIRP4KPMI75PHMPKPJ4IREHCMGPMR71MHXIMBDTIMSJXLMDTMSJXLMXDJMS7IRPJTM7H1MSJXLMXDJMS7IRPJTMS7IRPJT\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ',) - 0.19206\n",
      "('e',) - 0.10242\n",
      "('t',) - 0.06999\n",
      "('a',) - 0.06374\n",
      "('o',) - 0.06304\n",
      "('n',) - 0.05771\n",
      "('i',) - 0.05516\n",
      "('h',) - 0.05035\n",
      "('s',) - 0.05025\n",
      "('r',) - 0.04912\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for unigram, prob in list(ordered_ngrams(unigram_model))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('M',) - 0.17500\n",
      "('P',) - 0.11111\n",
      "('I',) - 0.07500\n",
      "('R',) - 0.07222\n",
      "('J',) - 0.06667\n",
      "('T',) - 0.05556\n",
      "('7',) - 0.05556\n",
      "('E',) - 0.05000\n",
      "('X',) - 0.04722\n",
      "('H',) - 0.04444\n"
     ]
    }
   ],
   "source": [
    "m1 = NGramModel(list(intercepted_in_jerusalem), 1)\n",
    "for unigram, prob in list(ordered_ngrams(m1))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ge CeI EH IRJXDCR IRe DH1eJCJXDH1 Re7IEHC T4TIeL ReJe DQ IRJXDCR IX IRe L7EH 7D1EeH2e 2R7LWeJ ReJe 7H1 QE07IeT GESeT We1JXXL ET ReJe R7KEHC CJ7WWe1 RET GESe Ge EHSXJL QE07Ie IR7I TRe ET EH XDJ 2DTIX14 7H1 SXJIRGEIR ETTDe XDJ 1eL7H1T IRe4Ke W0e1 DT GREIe IRe W7TI7J1T IRe4Ke I75eH eKeJ4IREHC Ge R71 HXI BDTI SJXL DT SJXL XDJ S7IReJT 7H1 SJXL XDJ S7IReJT S7IReJT\n"
     ]
    }
   ],
   "source": [
    "key = dict()\n",
    "key['M'] = ' '\n",
    "key['P'] = 'e'\n",
    "\n",
    "print(substitute(intercepted_in_jerusalem, key, replace=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P', 'M') - 0.04735\n",
      "('I', 'R') - 0.03900\n",
      "('R', 'P') - 0.03621\n",
      "('T', 'M') - 0.03064\n",
      "('M', 'I') - 0.02786\n",
      "('P', 'J') - 0.02507\n",
      "('E', 'H') - 0.01950\n",
      "('M', 'R') - 0.01950\n",
      "('J', 'X') - 0.01950\n",
      "('X', 'D') - 0.01950\n"
     ]
    }
   ],
   "source": [
    "m2 = NGramModel(list(intercepted_in_jerusalem), 2)\n",
    "for unigram, prob in list(ordered_ngrams(m2))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e', ' ') - 0.03374\n",
      "(' ', 't') - 0.02382\n",
      "('h', 'e') - 0.02164\n",
      "('d', ' ') - 0.02139\n",
      "(' ', 'a') - 0.02104\n",
      "('t', ' ') - 0.02060\n",
      "('t', 'h') - 0.01946\n",
      "('s', ' ') - 0.01832\n",
      "('e', 'r') - 0.01641\n",
      "(' ', 'h') - 0.01599\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for bigram, prob in list(ordered_ngrams(bigram_model))[:10]:\n",
    "    print(\"%s - %.5f\" % (bigram, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 words found\n",
      "['re', 'he', 'ye', 'me', 'be', 'we', 'de', 'se', 've']\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "for w in english_words:\n",
    "    if len(w) == 2 and w[1]=='e':\n",
    "        result.append(w)\n",
    "print(len(result), \"words found\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC\n",
    "\n",
    "* Choose the order of the n-gram model\n",
    "* Choose a reference text representing the language\n",
    " * Create an n-gram model from the reference text\n",
    "* For encrypted message\n",
    " * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "TRMIAG PUWSECHNDOLY\n",
      " ogwlrmcphniesaydut\n",
      "TRMIAGTPUWSECHNDOLY\n"
     ]
    }
   ],
   "source": [
    "n_order = 2\n",
    "def divergence():\n",
    "    pass\n",
    "\n",
    "austen_text\n",
    "reference_model = copy.deepcopy(quadgram_model)\n",
    "n_order = reference_model.order_\n",
    "\n",
    "encrypted_message = copy.deepcopy(intercepted_in_jerusalem)\n",
    "\n",
    "key = {'symbols': None, 'plain': None}\n",
    "chars_in_text = set(text)\n",
    "chars = \"\".join([e for e in chars_in_text])\n",
    "symbols = list(chars.upper())\n",
    "random.shuffle(symbols)\n",
    "symbols = \"\".join(symbols)\n",
    "\n",
    "def substitute(text, symbols, chars):\n",
    "    ret = text\n",
    "    for i in range(len(chars)):\n",
    "        ret = ret.replace(symbols[i], chars[i])\n",
    "    return ret\n",
    "\n",
    "print(symbols)\n",
    "print(chars)\n",
    "print(substitute(symbols, chars, symbols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_characters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
