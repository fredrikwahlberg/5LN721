{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some examples of substitution cryptos\n",
    "\n",
    "First, some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from ngram import NGramModel\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project gutenberg has some books that can easily be downloaded and used as reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available books: ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/fredrik/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "\n",
    "print(\"Available books:\", gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon\n",
    "\n",
    "A nice list of english words that could be used for comparing decoded data to real words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:07<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 36160 english (non-lemmatized) words in the extracted lexicon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fileids = gutenberg.fileids()\n",
    "if 'bible-kjv.txt' in fileids:\n",
    "    fileids.remove('bible-kjv.txt')\n",
    "all_words = set()\n",
    "for fileid in tqdm(fileids):\n",
    "    all_words.update(gutenberg.words(fileid))\n",
    "lexicon = set([e.lower() for e in all_words if e.isalpha()])\n",
    "\n",
    "print(\"We have %i english (non-lemmatized) words in the extracted lexicon\" % len(lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples from the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oarsmen', 'instigated', 'wig', 'architectural', 'soldier', 'conjured', 'cargoes', 'confounds', 'shellfish', 'effeminacy', 'daylight', 'cosa', 'promenade', 'bowels', 'insouciance', 'cannikin', 'envelopes', 'vapoured', 'questioning', 'confines']\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "print(choices(list(lexicon), k=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram models\n",
    "Let's clean up some Austen books as training data for the character models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had b\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.raw('austen-emma.txt')[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma by jane austen volume i chapter i emma woodhouse handsome clever and rich with a comfortable home and happy disposition seemed to unite some of the best blessings of existence and had lived nearly twentyone years in the world with very little to distress or vex her. she was the youngest of the two daughters of a most affectionate indulgent father and had in consequence of her sisters marriage been mistress of his house from a very early period. her mother had died too long ago for her to have more than an indistinct remembrance of her caresses and her place had been supplied by an excellent woman as governess who had fallen little short of a mother in affection. sixteen years had miss taylor been in mr. woodhouses family less as a governess than a friend very fond of both daughters bu\n"
     ]
    }
   ],
   "source": [
    "def generate_alphabet(alpha, omega):\n",
    "    \"\"\"Set of the english alphabet\"\"\"\n",
    "    return set([chr(i) for i in range(ord(alpha), ord(omega)+1)]) \n",
    "\n",
    "def clean_text(text, allowed):\n",
    "    ret = text.lower()\n",
    "    strip = set(ret).difference(allowed)\n",
    "    if \" \" in allowed:\n",
    "        for s in strip:\n",
    "            if s in ['\\n', '\\t']:\n",
    "                ret = ret.replace(s, \" \")\n",
    "            else:\n",
    "                ret = ret.replace(s, \"\")\n",
    "        for i in range(5): # HACK\n",
    "            ret = ret.replace(\"  \", \" \")\n",
    "    else:\n",
    "        for s in strip:\n",
    "            ret = ret.replace(s, \"\")\n",
    "    return ret\n",
    "\n",
    "alphabet = generate_alphabet('a', 'z') # Set of the english alphabet\n",
    "allowed_characters = set([' ', '.'])\n",
    "allowed_characters.update(alphabet)\n",
    "\n",
    "cleaned_text = clean_text(gutenberg.raw('austen-emma.txt'), allowed_characters)\n",
    "print(cleaned_text[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data cleaned, we are ready to create some character ngram models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 17.45it/s]\n"
     ]
    }
   ],
   "source": [
    "books = list()\n",
    "for fileid in tqdm(fileids):\n",
    "    books.append(clean_text(gutenberg.raw(fileid), allowed_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making n-gram models: 100%|██████████| 85/85 [01:14<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram model with 28 unique keys\n",
      "2-gram model with 690 unique keys\n",
      "3-gram model with 8517 unique keys\n",
      "4-gram model with 50795 unique keys\n"
     ]
    }
   ],
   "source": [
    "n_model = 5\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "grid = ParameterGrid({'data': books,\n",
    "                      'order': list(range(1, n_model+1))})\n",
    "\n",
    "def make_model(grid_point):\n",
    "    chars = list(grid_point['data'])\n",
    "    return NGramModel(chars, grid_point['order'])\n",
    "\n",
    "ngram_models = [None]*(n_model+1)\n",
    "with Pool(processes=os.cpu_count()) as process_pool:\n",
    "    for model in tqdm(process_pool.imap_unordered(make_model, grid),\n",
    "                      total=len(grid), desc=\"Making n-gram models\"):\n",
    "        if ngram_models[model.order_] is None:\n",
    "            ngram_models[model.order_] = model\n",
    "        else:\n",
    "            ngram_models[model.order_] = ngram_models[model.order_].union(model)\n",
    "\n",
    "for order in range(1, n_model):\n",
    "    print(ngram_models[order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram model: ut parhtroismu owfouarpww oeiao  o  e dt cidrnlmyaco e eeredtrmenln sfoaessliybs\n",
      "\n",
      "2-gram model: an t ror an. sphertevericly d onor fof antay gen dse s kish t whas. ticanole s f\n",
      "\n",
      "3-gram model: mbut once of has proby st fat on har lied le and frove sly th winfarm vould th b\n",
      "\n",
      "4-gram model: hat and a forwarneral and almsmalemed ther on quire the sticatic that reput tal \n",
      "\n",
      "5-gram model: smith he jem. the mosco my hope it but so. the similar fate better. volted from \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for order in range(1, n_model+1):\n",
    "    print(\"%i-gram model: %s\" % (order, \"\".join(ngram_models[order].predict_sequence(80))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the most common characters in this english text and their probabilities (from relative frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ', 't', 'h') - 0.01895\n",
      "('t', 'h', 'e') - 0.01476\n",
      "('h', 'e', ' ') - 0.01313\n",
      "('n', 'd', ' ') - 0.00780\n",
      "(' ', 'a', 'n') - 0.00755\n",
      "('a', 'n', 'd') - 0.00718\n",
      "('e', 'd', ' ') - 0.00620\n",
      "('i', 'n', 'g') - 0.00588\n",
      "(' ', 't', 'o') - 0.00571\n",
      "('e', 'r', ' ') - 0.00565\n"
     ]
    }
   ],
   "source": [
    "order = 3\n",
    "\n",
    "from ngram import ordered_ngrams\n",
    "for key, prob in list(ordered_ngrams(ngram_models[order]))[:10]:\n",
    "    print(\"%s - %.5f\" % (key, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caesar substitution crypto\n",
    "Maybe the most basic substitution crypto, based on charcter rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YNNOVLONY\n"
     ]
    }
   ],
   "source": [
    "def caesar_encryption(word, offset=3):\n",
    "    enc = [chr(ord(char)+offset-len(alphabet)) if (ord(char)+offset)>ord('z') else chr(ord(char)+offset)\n",
    "           for char in word.lower() if char in alphabet]\n",
    "    return \"\".join(enc).upper()\n",
    "\n",
    "import random\n",
    "offset = random.randint(1, len(alphabet)-1)\n",
    "\n",
    "print(caesar_encryption(\"Et tu brute\", offset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for finding the key to an unknown cryptogram (assuming it's a caesar crypto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_to_alesia = \"YHUFLQJHWRULABRXUPRWKHUZDVDKDPVWHUDQGBRXUIDWKHUVPHOOVRIHOGHUEHUULHV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('H',) - 0.14925\n",
      "('U',) - 0.14925\n",
      "('V',) - 0.07463\n",
      "('D',) - 0.07463\n",
      "('R',) - 0.07463\n",
      "('W',) - 0.05970\n",
      "('L',) - 0.04478\n",
      "('K',) - 0.04478\n",
      "('P',) - 0.04478\n",
      "('O',) - 0.04478\n",
      "('B',) - 0.02985\n",
      "('I',) - 0.02985\n",
      "('G',) - 0.02985\n",
      "('X',) - 0.02985\n",
      "('Q',) - 0.02985\n",
      "('F',) - 0.01493\n",
      "('E',) - 0.01493\n",
      "('J',) - 0.01493\n",
      "('A',) - 0.01493\n",
      "('Z',) - 0.01493\n",
      "('Y',) - 0.01493\n"
     ]
    }
   ],
   "source": [
    "caesar_model = NGramModel(list(message_to_alesia), 1)\n",
    "for unigram, prob in list(ordered_ngrams(caesar_model)):\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_decode(text, offset):\n",
    "    ret = str()\n",
    "    for i in range(len(text)):\n",
    "        c = ord(text[i]) - offset\n",
    "        if c > ord('Z'):\n",
    "            c -= len(alphabet)\n",
    "        if c < ord('A'):\n",
    "            c += len(alphabet)\n",
    "        ret += chr(c)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vercingetorixyourmotherwasahamsterandyourfathersmellsofelderberries\n"
     ]
    }
   ],
   "source": [
    "n_key = 3\n",
    "message_from_caesar = caesar_decode(message_to_alesia, n_key)\n",
    "print(message_from_caesar.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something we can do to solve this, but would be harder for the romans, is to let a computer brute force this. However short the message we could try every solution and compare to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 xgtekpigvqtkzaqwtoqvjgtycucjcouvgtcpfaqwthcvjgtuognnuqhgnfgtdgttkgu\n",
      "2 wfsdjohfupsjyzpvsnpuifsxbtbibntufsboezpvsgbuifstnfmmtpgfmefscfssjft\n",
      "3 vercingetorixyourmotherwasahamsterandyourfathersmellsofelderberries\n",
      "4 udqbhmfdsnqhwxntqlnsgdqvzrzgzlrsdqzmcxntqezsgdqrldkkrnedkcdqadqqhdr\n",
      "5 tcpaglecrmpgvwmspkmrfcpuyqyfykqrcpylbwmspdyrfcpqkcjjqmdcjbcpzcppgcq\n",
      "6 sbozfkdbqlofuvlrojlqebotxpxexjpqboxkavlrocxqebopjbiiplcbiaboyboofbp\n",
      "7 ranyejcapknetukqnikpdanswowdwiopanwjzukqnbwpdanoiahhokbahzanxanneao\n",
      "8 qzmxdibzojmdstjpmhjoczmrvnvcvhnozmviytjpmavoczmnhzggnjazgyzmwzmmdzn\n",
      "9 pylwchaynilcrsiolginbylqumubugmnyluhxsiolzunbylmgyffmizyfxylvyllcym\n",
      "10 oxkvbgzxmhkbqrhnkfhmaxkptltatflmxktgwrhnkytmaxklfxeelhyxewxkuxkkbxl\n",
      "11 nwjuafywlgjapqgmjeglzwjoskszseklwjsfvqgmjxslzwjkewddkgxwdvwjtwjjawk\n",
      "12 mvitzexvkfizopflidfkyvinrjryrdjkvireupfliwrkyvijdvccjfwvcuvisviizvj\n",
      "13 luhsydwujehynoekhcejxuhmqiqxqcijuhqdtoekhvqjxuhicubbievubtuhruhhyui\n",
      "14 ktgrxcvtidgxmndjgbdiwtglphpwpbhitgpcsndjgupiwtghbtaahdutastgqtggxth\n",
      "15 jsfqwbushcfwlmcifachvsfkogovoaghsfobrmciftohvsfgaszzgctszrsfpsffwsg\n",
      "16 irepvatrgbevklbhezbgurejnfnunzfgrenaqlbhesngurefzryyfbsryqreoreevrf\n",
      "17 hqdouzsqfadujkagdyaftqdimemtmyefqdmzpkagdrmftqdeyqxxearqxpqdnqdduqe\n",
      "18 gpcntyrpezctijzfcxzespchldlslxdepclyojzfcqlespcdxpwwdzqpwopcmpcctpd\n",
      "19 fobmsxqodybshiyebwydrobgkckrkwcdobkxniyebpkdrobcwovvcypovnoblobbsoc\n",
      "20 enalrwpncxarghxdavxcqnafjbjqjvbcnajwmhxdaojcqnabvnuubxonumnaknaarnb\n",
      "21 dmzkqvombwzqfgwczuwbpmzeiaipiuabmzivlgwcznibpmzaumttawnmtlmzjmzzqma\n",
      "22 clyjpunlavypefvbytvaolydhzhohtzalyhukfvbymhaolyztlsszvmlsklyilyyplz\n",
      "23 bkxiotmkzuxodeuaxsuznkxcgygngsyzkxgtjeuaxlgznkxyskrryulkrjkxhkxxoky\n",
      "24 ajwhnsljytwncdtzwrtymjwbfxfmfrxyjwfsidtzwkfymjwxrjqqxtkjqijwgjwwnjx\n",
      "25 zivgmrkixsvmbcsyvqsxlivaeweleqwxiverhcsyvjexlivwqippwsjiphivfivvmiw\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, len(alphabet)):\n",
    "    print(n, caesar_decode(message_to_alesia, n).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-one substitution crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O9WLCNL9JCNL9TANFE1WATCNTDALNBE1DCNZTEZ5TNVW55TBNFE1WATCNL9T3N8ENL9TN9EDCTNJLNCW3CNFE1WACN8EN9E1T\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Whats this then Romanes eunt domus People called Romanes they go the house It says Romans go home\"\"\"\n",
    "#def encrypt_substitution(text):\n",
    "text = text.lower()\n",
    "unenc = list(set(text))\n",
    "symbols = [c.upper() for c in alphabet]\n",
    "symbols.extend(list(\"0123456789\"))\n",
    "s = list(symbols)\n",
    "random.shuffle(s)\n",
    "enc = s[:len(unenc)]\n",
    "\n",
    "key = dict()\n",
    "for a, b in zip(unenc, enc):\n",
    "    key[a] = b\n",
    "\n",
    "def substitute(text, encryption_key, replace=\"-\"):\n",
    "    ret = str()\n",
    "    for c in text:\n",
    "        if c in encryption_key.keys():\n",
    "            ret += encryption_key[c]\n",
    "        else:\n",
    "            if replace is not None:\n",
    "                ret += replace\n",
    "            else:\n",
    "                ret += c\n",
    "    return ret\n",
    "\n",
    "enc_text = substitute(text, key)\n",
    "print(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 'V',\n",
       " 'r': 'F',\n",
       " ' ': 'N',\n",
       " 't': 'L',\n",
       " 'g': '8',\n",
       " 'e': 'T',\n",
       " 'l': '5',\n",
       " 'd': 'B',\n",
       " 'u': 'D',\n",
       " 'h': '9',\n",
       " 's': 'C',\n",
       " 'o': 'E',\n",
       " 'y': '3',\n",
       " 'w': 'O',\n",
       " 'p': 'Z',\n",
       " 'i': 'J',\n",
       " 'm': '1',\n",
       " 'a': 'W',\n",
       " 'n': 'A'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V': 'c',\n",
       " 'F': 'r',\n",
       " 'N': ' ',\n",
       " 'L': 't',\n",
       " '8': 'g',\n",
       " 'T': 'e',\n",
       " '5': 'l',\n",
       " 'B': 'd',\n",
       " 'D': 'u',\n",
       " '9': 'h',\n",
       " 'C': 's',\n",
       " 'E': 'o',\n",
       " '3': 'y',\n",
       " 'O': 'w',\n",
       " 'Z': 'p',\n",
       " 'J': 'i',\n",
       " '1': 'm',\n",
       " 'W': 'a',\n",
       " 'A': 'n'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_key = dict()\n",
    "for a, b in [(k, key[k]) for k in key.keys()]:\n",
    "    reverse_key[b] = a\n",
    "reverse_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats this then romanes eunt domus people called romanes they go the house it says romans go home\n"
     ]
    }
   ],
   "source": [
    "print(substitute(enc_text, reverse_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPMCPIMEHMIRJXDCRMIRPMDH1PJCJXDH1MRP7IEHCMT4TIPLMRPJPMDQMIRJXDCRMIXMIRPML7EHM7D1EPH2PM2R7LWPJMRPJPM7H1MQE07IPTMGESPTMWP1JXXLMETMRPJPMR7KEHCMCJ7WWP1MRETMGESPMGPMEHSXJLMQE07IPMIR7IMTRPMETMEHMXDJM2DTIX14M7H1MSXJIRGEIRMETTDPMXDJM1PL7H1TMIRP4KPMW0P1MDTMGREIPMIRPMW7TI7J1TMIRP4KPMI75PHMPKPJ4IREHCMGPMR71MHXIMBDTIMSJXLMDTMSJXLMXDJMS7IRPJTM7H1MSJXLMXDJMS7IRPJTMS7IRPJT\n"
     ]
    }
   ],
   "source": [
    "intercepted_in_jerusalem = \"\"\"GPMCPIMEHMIRJXDCRMIRPMDH1PJCJXDH1MRP7IEHCMT4TIPLMRPJPMDQMIRJXDCRMIXMIRPML7EHM7D1EPH2PM2R7LWPJMRPJPM7H1MQE07IPTMGESPTMWP1JXXLMETMRPJPMR7KEHCMCJ7WWP1MRETMGESPMGPMEHSXJLMQE07IPMIR7IMTRPMETMEHMXDJM2DTIX14M7H1MSXJIRGEIRMETTDPMXDJM1PL7H1TMIRP4KPMW0P1MDTMGREIPMIRPMW7TI7J1TMIRP4KPMI75PHMPKPJ4IREHCMGPMR71MHXIMBDTIMSJXLMDTMSJXLMXDJMS7IRPJTM7H1MSJXLMXDJMS7IRPJTMS7IRPJT\"\"\"\n",
    "print(intercepted_in_jerusalem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ',) - 0.18567\n",
      "('e',) - 0.10031\n",
      "('t',) - 0.07226\n",
      "('a',) - 0.06456\n",
      "('o',) - 0.06171\n",
      "('n',) - 0.05531\n",
      "('i',) - 0.05443\n",
      "('h',) - 0.05213\n",
      "('s',) - 0.05199\n",
      "('r',) - 0.04713\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for unigram, prob in list(ordered_ngrams(ngram_models[1]))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('M',) - 0.17500\n",
      "('P',) - 0.11111\n",
      "('I',) - 0.07500\n",
      "('R',) - 0.07222\n",
      "('J',) - 0.06667\n",
      "('T',) - 0.05556\n",
      "('7',) - 0.05556\n",
      "('E',) - 0.05000\n",
      "('X',) - 0.04722\n",
      "('H',) - 0.04444\n"
     ]
    }
   ],
   "source": [
    "m1 = NGramModel(list(intercepted_in_jerusalem), 1)\n",
    "for unigram, prob in list(ordered_ngrams(m1))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ge CeI EH IRJXDCR IRe DH1eJCJXDH1 Re7IEHC T4TIeL ReJe DQ IRJXDCR IX IRe L7EH 7D1EeH2e 2R7LWeJ ReJe 7H1 QE07IeT GESeT We1JXXL ET ReJe R7KEHC CJ7WWe1 RET GESe Ge EHSXJL QE07Ie IR7I TRe ET EH XDJ 2DTIX14 7H1 SXJIRGEIR ETTDe XDJ 1eL7H1T IRe4Ke W0e1 DT GREIe IRe W7TI7J1T IRe4Ke I75eH eKeJ4IREHC Ge R71 HXI BDTI SJXL DT SJXL XDJ S7IReJT 7H1 SJXL XDJ S7IReJT S7IReJT\n"
     ]
    }
   ],
   "source": [
    "key = dict()\n",
    "key['M'] = ' '\n",
    "key['P'] = 'e'\n",
    "\n",
    "print(substitute(intercepted_in_jerusalem, key, replace=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P', 'M') - 0.04735\n",
      "('I', 'R') - 0.03900\n",
      "('R', 'P') - 0.03621\n",
      "('T', 'M') - 0.03064\n",
      "('M', 'I') - 0.02786\n",
      "('P', 'J') - 0.02507\n",
      "('E', 'H') - 0.01950\n",
      "('M', 'R') - 0.01950\n",
      "('J', 'X') - 0.01950\n",
      "('X', 'D') - 0.01950\n"
     ]
    }
   ],
   "source": [
    "m2 = NGramModel(list(intercepted_in_jerusalem), 2)\n",
    "for unigram, prob in list(ordered_ngrams(m2))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e', ' ') - 0.03517\n",
      "(' ', 't') - 0.02770\n",
      "('t', 'h') - 0.02415\n",
      "('h', 'e') - 0.02284\n",
      "('d', ' ') - 0.02077\n",
      "(' ', 'a') - 0.02064\n",
      "('s', ' ') - 0.01926\n",
      "('t', ' ') - 0.01918\n",
      "(' ', 's') - 0.01478\n",
      "('i', 'n') - 0.01457\n"
     ]
    }
   ],
   "source": [
    "for bigram, prob in list(ordered_ngrams(ngram_models[2]))[:10]:\n",
    "    print(\"%s - %.5f\" % (bigram, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 words found\n",
      "['we', 'te', 'he', 'ye', 'le', 'ne', 'me', 'se', 'ge', 'be', 'ee', 've', 're', 'de', 'fe', 'pe', 'ze', 'ue']\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "for w in lexicon:\n",
    "    if len(w) == 2 and w[1]=='e':\n",
    "        result.append(w)\n",
    "print(len(result), \"words found\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted symbols: XER75SMWIJ01Q2H4TGPDCBKL\n",
      "Decrypted symbols: gbtuidsqpvyhmncafljew xroz.k\n"
     ]
    }
   ],
   "source": [
    "encrypted_message = intercepted_in_jerusalem\n",
    "encrypted_symbols = np.unique(list(encrypted_message))\n",
    "random.shuffle(encrypted_symbols)\n",
    "encrypted_symbols = \"\".join(encrypted_symbols)\n",
    "print(\"Encrypted symbols:\", encrypted_symbols)\n",
    "\n",
    "decrypted_symbols = [k[0] for k in ngram_models[1].keys()]\n",
    "random.shuffle(decrypted_symbols)\n",
    "decrypted_symbols = \"\".join(decrypted_symbols)\n",
    "print(\"Decrypted symbols:\", decrypted_symbols)\n",
    "\n",
    "assert len(set(decrypted_symbols).intersection(set(encrypted_symbols)))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model: 2-gram model with 690 unique keys\n",
      "log P: -3779.7640096310993\n"
     ]
    }
   ],
   "source": [
    "n_order = 2\n",
    "reference_model = ngram_models[n_order]\n",
    "print(\"Reference model:\", reference_model)\n",
    "\n",
    "# Define a substitution function\n",
    "import copy\n",
    "def decode(encrypted_message, encrypted_symbols, decrypted_symbols):\n",
    "    ret = copy.copy(encrypted_message)\n",
    "    for e, d in zip(list(encrypted_symbols), list(decrypted_symbols)):\n",
    "        ret = ret.replace(e, d)\n",
    "    return ret\n",
    "\n",
    "# Define a probability function\n",
    "from ngram import grouping_tokenizer\n",
    "M = dict()\n",
    "for ngram, prob in list(ordered_ngrams(reference_model)):\n",
    "    M[ngram] = np.log(prob)\n",
    "M_min = np.min(list(M.values()))-2\n",
    "\n",
    "def P(decrypted_message):\n",
    "    s = 0\n",
    "    for ngram in grouping_tokenizer(n_order).tokenize(list(decrypted_message)):\n",
    "        if ngram in M:\n",
    "            s += M[ngram]\n",
    "        else:\n",
    "            s += M_min\n",
    "    return s\n",
    "\n",
    "decrypted_message = decode(encrypted_message, encrypted_symbols, decrypted_symbols)\n",
    "p = P(decrypted_message)\n",
    "print(\"log P:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, logP=-3779.8 : ljswjpsbqsptvgewtsptjseqhjvwvgeqhstjupbqwsfafpjrstjvjsemsptv\n",
      "iter 250, logP=-2152.2 : me geb on bradugr bre unheagadunh reibong flfbe. reae uc bra\n",
      "iter 500, logP=-1953.6 : ce get on tharugh the undeagarund heitong slste. heae uy tha\n",
      "iter 750, logP=-1940.7 : fe get on tharugh the undeagarund heitong s.stel heae uy tha\n",
      "iter 1000, logP=-1893.0 : we get oq thraugh the uqdergrauqd heitoqg s.stel here uy thr\n",
      "iter 1250, logP=-1893.0 : we get on txraugx txe undergraund xeitong s.stel xere uy txr\n",
      "iter 1500, logP=-1893.0 : we get oj thraugh the ujdergraujd heitojg s.stel here uy thr\n",
      "iter 1750, logP=-1867.1 : we ge. an .hrough .he underground hei.ang sts.el here uy .hr\n",
      "iter 2000, logP=-1854.5 : we get in thbough the undebgbound heating system hebe u. thb\n",
      "iter 2250, logP=-1849.3 : we get in through the unjergrounj heating s.stem here uy thr\n",
      "iter 2500, logP=-1850.6 : we get in tbrougb tbe underground beating s.stef bere uy tbr\n",
      "iter 2750, logP=-1846.3 : we .et in throu.h the under.round heatin. sgstef here up thr\n",
      "iter 3000, logP=-1846.3 : we get in through the underground he.ting sastef here up thr\n",
      "iter 3250, logP=-1846.3 : we get in through the uncergrounc heating s.stef here up thr\n",
      "iter 3500, logP=-1846.3 : we get in through the underground he.ting sastef here up thr\n",
      "iter 3750, logP=-1846.3 : we get in through the unbergrounb heating s.stef here up thr\n",
      "iter 4000, logP=-1846.3 : we get in thrcugh the undergrcund heating s.stef here up thr\n",
      "iter 4250, logP=-1846.3 : we get in thqough the undeqgqound heating s.stef heqe up thq\n",
      "iter 4500, logP=-1848.5 : we zet in throuzh the underzround heatinz s.stef here uy thr\n",
      "iter 4750, logP=-1846.3 : we get in thjough the undejgjound heating s.stef heje up thj\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(5000):\n",
    "    # Pick symbols to switch\n",
    "    p1 = np.random.randint(len(decrypted_symbols))\n",
    "    p2 = np.random.randint(len(decrypted_symbols))\n",
    "    while p1 == p2:\n",
    "        p2 = np.random.randint(len(decrypted_symbols))\n",
    "    new_decrypted_symbols = list(decrypted_symbols)\n",
    "    new_decrypted_symbols[p2] = decrypted_symbols[p1]\n",
    "    new_decrypted_symbols[p1] = decrypted_symbols[p2]\n",
    "    new_decrypted_symbols = \"\".join(new_decrypted_symbols)\n",
    "\n",
    "    decrypted_message = decode(encrypted_message, encrypted_symbols, new_decrypted_symbols)\n",
    "#    model = NGramModel(decrypted_message, n_order)\n",
    "\n",
    "#    decrypted_vector = model.vectorize(codebook=reference_model.keys())\n",
    "    \n",
    "    p_star = P(decrypted_message)\n",
    "\n",
    "    #print(div(reference_vector, decrypted_vector))\n",
    "    if np.random.uniform() < np.exp(p_star - p):\n",
    "        decrypted_symbols = new_decrypted_symbols\n",
    "        p = p_star\n",
    "    if iteration % 250 == 0:\n",
    "        print(\"iter %i, logP=%.1f : %s\" % (iteration, p, decrypted_message[:60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XER75SMWIJ01Q2H4TGPDCBKL => oihakm ltrvdpcn.sweugbyfjzxq\n",
      "\n",
      "GPMCPIMEHMIRJXDCRMIRPMDH1PJCJXDH1MRP7IEHCMT4TIPLMRPJPMDQMIRJXDCRMIXMIRPML7EHM7D1EPH2PM2R7LWPJMRPJPM7H1MQE07IPTMGESPTMWP1JXXLMETMRPJPMR7KEHCMCJ7WWP1MRETMGESPMGPMEHSXJLMQE07IPMIR7IMTRPMETMEHMXDJM2DTIX14M7H1MSXJIRGEIRMETTDPMXDJM1PL7H1TMIRP4KPMW0P1MDTMGREIPMIRPMW7TI7J1TMIRP4KPMI75PHMPKPJ4IREHCMGPMR71MHXIMBDTIMSJXLMDTMSJXLMXDJMS7IRPJTM7H1MSJXLMXDJMS7IRPJTMS7IRPJT\n",
      "wz gzt in through thz undzrground hzating s.stzf hzrz up through to thz fain audizncz chaflzr hzrz and pivatzs wimzs lzdroof is hzrz haying grallzd his wimz wz inmorf pivatz that shz is in our custod. and morthwith issuz our dzfands thz.yz lvzd us whitz thz lastards thz.yz takzn zyzr.thing wz had not bust mrof us mrof our mathzrs and mrof our mathzrs mathzrs\n"
     ]
    }
   ],
   "source": [
    "print(encrypted_symbols, \"=>\", decrypted_symbols)\n",
    "print()\n",
    "print(encrypted_message)\n",
    "print(decrypted_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
